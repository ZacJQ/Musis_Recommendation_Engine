{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/zac/Codes/Music_Project/GIT_HUB/Musis_Recommendation_Engine/data/testing/testing.csv')\n",
    "\n",
    "# Ensure there are no missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Preprocess the features (scaling numeric features)\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['popularity', 'danceability', 'energy', 'key', 'loudness', \n",
    "                    'mode', 'speechiness', 'acousticness', 'instrumentalness', \n",
    "                    'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "# Encode the mood as a numerical value\n",
    "data['mood'] = data['mood'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Dense(128, activation='relu')(input)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (len(numeric_features) + 1, )\n",
    "\n",
    "# Create the base network\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "# Create the inputs\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# Create the outputs\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Define the distance function\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "# Calculate the distance\n",
    "distance = Lambda(euclidean_distance, output_shape=(1,))([processed_a, processed_b])\n",
    "\n",
    "# Create the model\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(pairs), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create pairs and labels\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m pairs, labels \u001b[38;5;241m=\u001b[39m create_pairs(data[numeric_features \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmood\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmood\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Split into training and validation sets\u001b[39;00m\n\u001b[1;32m     28\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pairs) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mcreate_pairs\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[1;32m     12\u001b[0m     current_sample \u001b[38;5;241m=\u001b[39m data[idx]\n\u001b[0;32m---> 13\u001b[0m     current_label \u001b[38;5;241m=\u001b[39m labels[idx]\n\u001b[1;32m     15\u001b[0m     positive_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(label_to_indices[current_label])\n\u001b[1;32m     16\u001b[0m     negative_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(unique_labels[unique_labels \u001b[38;5;241m!=\u001b[39m current_label])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to create pairs of samples and labels\n",
    "def create_pairs(data, labels):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    label_to_indices = {label: np.where(labels == label)[0] for label in unique_labels}\n",
    "    \n",
    "    for idx in range(len(data)):\n",
    "        current_sample = data[idx]\n",
    "        current_label = labels[idx]\n",
    "        \n",
    "        positive_idx = np.random.choice(label_to_indices[current_label])\n",
    "        negative_label = np.random.choice(unique_labels[unique_labels != current_label])\n",
    "        negative_idx = np.random.choice(label_to_indices[negative_label])\n",
    "        \n",
    "        pairs += [[current_sample, data[positive_idx]], [current_sample, data[negative_idx]]]\n",
    "        labels += [1, 0]\n",
    "    \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "# Create pairs and labels\n",
    "pairs, labels = create_pairs(data[numeric_features + ['mood']].values, data['mood'].values)\n",
    "\n",
    "# Split into training and validation sets\n",
    "split = int(len(pairs) * 0.8)\n",
    "pairs_train, pairs_val = pairs[:split], pairs[split:]\n",
    "labels_train, labels_val = labels[:split], labels[split:]\n",
    "\n",
    "# Train the model\n",
    "model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train, \n",
    "          validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val), \n",
    "          epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to create pairs of samples and labels\n",
    "def create_pairs(data, labels):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    label_to_indices = {label: np.where(labels == label)[0] for label in unique_labels}\n",
    "    \n",
    "    for idx in range(len(data)):\n",
    "        current_sample = data[idx]\n",
    "        current_label = labels[idx]\n",
    "        \n",
    "        positive_idx = np.random.choice(label_to_indices[current_label])\n",
    "        negative_label = np.random.choice(unique_labels[unique_labels != current_label])\n",
    "        negative_idx = np.random.choice(label_to_indices[negative_label])\n",
    "        \n",
    "        pairs += [[current_sample, data[positive_idx]], [current_sample, data[negative_idx]]]\n",
    "        labels += [1, 0]\n",
    "    \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "# Create pairs and labels\n",
    "pairs, labels = create_pairs(data[numeric_features + ['mood']].values, data['mood'].values)\n",
    "\n",
    "# Split into training and validation sets\n",
    "split = int(len(pairs) * 0.8)\n",
    "pairs_train, pairs_val = pairs[:split], pairs[split:]\n",
    "labels_train, labels_val = labels[:split], labels[split:]\n",
    "\n",
    "# Train the model\n",
    "model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train, \n",
    "          validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val), \n",
    "          epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the embedding of a sample\n",
    "def compute_embedding(sample):\n",
    "    return base_network.predict(sample.reshape(1, -1))\n",
    "\n",
    "# Function to recommend songs based on mood\n",
    "def recommend_songs(user_mood, num_recommendations=5):\n",
    "    # Convert mood to the same encoding as the data\n",
    "    user_mood_code = pd.Series([user_mood]).astype('category').cat.codes.values[0]\n",
    "    \n",
    "    # Create a sample input with the specified mood\n",
    "    sample_input = np.zeros((1, len(numeric_features) + 1))\n",
    "    sample_input[0, -1] = user_mood_code  # Set mood\n",
    "    sample_input[0, :-1] = np.mean(data[numeric_features], axis=0)  # Set average values for other features\n",
    "    \n",
    "    # Compute the embedding of the sample input\n",
    "    sample_embedding = compute_embedding(sample_input[0])\n",
    "    \n",
    "    # Compute the distances to all other samples\n",
    "    distances = np.linalg.norm(base_network.predict(data[numeric_features + ['mood']].values) - sample_embedding, axis=1)\n",
    "    \n",
    "    # Get the indices of the closest samples\n",
    "    recommendation_indices = np.argsort(distances)[:num_recommendations]\n",
    "    \n",
    "    recommendations = data.iloc[recommendation_indices]\n",
    "    return recommendations[['song_name', 'artist_name']]\n",
    "\n",
    "# Example usage\n",
    "print(recommend_songs('happy', num_recommendations=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
